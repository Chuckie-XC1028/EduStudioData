2023-12-05 17:22:03[INFO]: ============================================================
2023-12-05 17:22:03[INFO]: [ID]: 2023-12-05-172202
2023-12-05 17:22:03[INFO]: [DATASET]: FrcSub
2023-12-05 17:22:03[INFO]: [ARGV]: ['run_dina_demo.py']
2023-12-05 17:22:03[INFO]: [ALL_CFG]: 
{
    "traintpl_cfg": {
        "cls": "EduTrainTPL",
        "num_stop_rounds": 10,
        "early_stop_metrics": [
            [
                "auc",
                "max"
            ]
        ],
        "best_epoch_metric": "auc",
        "unsave_best_epoch_pth": true,
        "ignore_metrics_in_train": [],
        "batch_size": 32,
        "device": "cpu",
        "epoch_num": 100,
        "eval_batch_size": 2048,
        "num_workers": 0,
        "lr": 0.001,
        "optim": "adam",
        "eps": 1e-08,
        "weight_decay": 0.0,
        "seed": 2023
    },
    "datatpl_cfg": {
        "cls": "CDInterExtendsQDataTPL",
        "mid2cache_op_seq": [
            "M2C_Label2Int",
            "M2C_FilterRecords4CD",
            "M2C_ReMapId",
            "M2C_RandomDataSplit4CD",
            "M2C_GenQMat"
        ],
        "exer_exclude_feat_names": [],
        "stu_exclude_feat_names": [],
        "seperator": ",",
        "n_folds": 1,
        "is_dataset_divided": false,
        "is_save_cache": false,
        "cache_id": "cache_default",
        "load_data_from": "middata",
        "inter_exclude_feat_names": [],
        "raw2mid_op": null,
        "seed": 2023,
        "M2C_Label2Int": {},
        "M2C_FilterRecords4CD": {
            "stu_least_records": 10,
            "exer_least_records": 0
        },
        "M2C_ReMapId": {
            "share_id_columns": [],
            "ignore_columns": "{'order_id:token'}"
        },
        "M2C_RandomDataSplit4CD": {
            "seed": 2023,
            "divide_scale_list": [
                7,
                1,
                2
            ]
        },
        "M2C_GenQMat": {}
    },
    "modeltpl_cfg": {
        "cls": "DINA",
        "step": 0,
        "max_step": 1000,
        "max_slip": 0.4,
        "max_guess": 0.4,
        "param_init_type": "xavier_normal",
        "pretrained_file_path": ""
    },
    "evaltpl_cfg": {
        "clses": [
            "BinaryClassificationEvalTPL",
            "CognitiveDiagnosisEvalTPL"
        ],
        "BinaryClassificationEvalTPL": {
            "use_metrics": [
                "auc",
                "acc",
                "rmse"
            ]
        },
        "CognitiveDiagnosisEvalTPL": {
            "use_metrics": [
                "doa_all"
            ],
            "test_only_metrics": [
                "doa_all"
            ]
        }
    },
    "frame_cfg": {
        "ARCHIVE_FOLDER_PATH": "/home/u2022171244/EduStudio-main/examples/single_model/archive",
        "CFG_FOLDER_PATH": "/home/u2022171244/EduStudio-main/examples/single_model/conf",
        "DATA_FOLDER_PATH": "/home/u2022171244/EduStudio-main/examples/single_model/data",
        "DISABLE_LOG_STDOUT": false,
        "DISABLE_TQDM_BAR": false,
        "DT_INFO_DICT": {},
        "DT_INFO_FILE_PATH": "/home/u2022171244/EduStudio-main/edustudio/assets/datasets.yaml",
        "ID": "2023-12-05-172202",
        "LOG_WITHOUT_DATE": false,
        "TEMP_FOLDER_PATH": "/home/u2022171244/EduStudio-main/examples/single_model/temp",
        "TQDM_NCOLS": 100,
        "WORK_DIR": "/home/u2022171244/EduStudio-main/examples/single_model",
        "data_folder_path": "/home/u2022171244/EduStudio-main/examples/single_model/data/FrcSub",
        "temp_folder_path": "/home/u2022171244/EduStudio-main/examples/single_model/temp/FrcSub/EduTrainTPL/DINA/2023-12-05-172202",
        "archive_folder_path": "/home/u2022171244/EduStudio-main/examples/single_model/archive/FrcSub/EduTrainTPL/DINA"
    },
    "dataset": "FrcSub",
    "logger": "<Logger edustudio (DEBUG)>"
}
2023-12-05 17:22:03[INFO]: ============================================================
2023-12-05 17:22:03[INFO]: {'stu_count': 536, 'exer_count': 20, 'cpt_count': 8}
2023-12-05 17:22:03[INFO]: TrainTPL <class 'edustudio.traintpl.edu_traintpl.EduTrainTPL'> Started!
2023-12-05 17:22:03[INFO]: ====== [FOLD ID]: 0 ======
2023-12-05 17:22:03[INFO]: [CALLBACK]-ModelCheckPoint has been registered!
2023-12-05 17:22:03[INFO]: [CALLBACK]-EarlyStopping has been registered!
2023-12-05 17:22:03[INFO]: [CALLBACK]-History has been registered!
2023-12-05 17:22:03[INFO]: [CALLBACK]-BaseLogger has been registered!
2023-12-05 17:22:03[INFO]: Start Training...
2023-12-05 17:22:04[INFO]: Update best epoch as [1] for auc!
2023-12-05 17:22:04[INFO]: [EPOCH=001]: loss_main: 0.6952
2023-12-05 17:22:04[INFO]: [EPOCH=001]: auc: 0.6004 | acc: 0.5905 | rmse: 0.5389
2023-12-05 17:22:04[INFO]: Update best epoch as [2] for auc!
2023-12-05 17:22:04[INFO]: [EPOCH=002]: loss_main: 0.6906
2023-12-05 17:22:04[INFO]: [EPOCH=002]: auc: 0.6785 | acc: 0.6427 | rmse: 0.5058
2023-12-05 17:22:04[INFO]: Update best epoch as [3] for auc!
2023-12-05 17:22:04[INFO]: [EPOCH=003]: loss_main: 0.6855
2023-12-05 17:22:04[INFO]: [EPOCH=003]: auc: 0.7675 | acc: 0.7183 | rmse: 0.4557
2023-12-05 17:22:05[INFO]: Update best epoch as [4] for auc!
2023-12-05 17:22:05[INFO]: [EPOCH=004]: loss_main: 0.6519
2023-12-05 17:22:05[INFO]: [EPOCH=004]: auc: 0.7967 | acc: 0.7341 | rmse: 0.4430
2023-12-05 17:22:05[INFO]: Update best epoch as [5] for auc!
2023-12-05 17:22:05[INFO]: [EPOCH=005]: loss_main: 0.6792
2023-12-05 17:22:05[INFO]: [EPOCH=005]: auc: 0.8008 | acc: 0.7351 | rmse: 0.4408
2023-12-05 17:22:06[INFO]: Update best epoch as [6] for auc!
2023-12-05 17:22:06[INFO]: [EPOCH=006]: loss_main: 0.6764
2023-12-05 17:22:06[INFO]: [EPOCH=006]: auc: 0.8042 | acc: 0.7351 | rmse: 0.4393
2023-12-05 17:22:06[INFO]: Update best epoch as [7] for auc!
2023-12-05 17:22:06[INFO]: [EPOCH=007]: loss_main: 0.6732
2023-12-05 17:22:06[INFO]: [EPOCH=007]: auc: 0.8065 | acc: 0.7341 | rmse: 0.4387
2023-12-05 17:22:07[INFO]: Update best epoch as [8] for auc!
2023-12-05 17:22:07[INFO]: [EPOCH=008]: loss_main: 0.6331
2023-12-05 17:22:07[INFO]: [EPOCH=008]: auc: 0.8210 | acc: 0.7491 | rmse: 0.4277
2023-12-05 17:22:07[INFO]: Update best epoch as [9] for auc!
2023-12-05 17:22:07[INFO]: [EPOCH=009]: loss_main: 0.6686
2023-12-05 17:22:07[INFO]: [EPOCH=009]: auc: 0.8221 | acc: 0.7500 | rmse: 0.4261
2023-12-05 17:22:07[INFO]: Update best epoch as [10] for auc!
2023-12-05 17:22:07[INFO]: [EPOCH=010]: loss_main: 0.6672
2023-12-05 17:22:07[INFO]: [EPOCH=010]: auc: 0.8237 | acc: 0.7509 | rmse: 0.4246
2023-12-05 17:22:08[INFO]: Update best epoch as [11] for auc!
2023-12-05 17:22:08[INFO]: [EPOCH=011]: loss_main: 0.6654
2023-12-05 17:22:08[INFO]: [EPOCH=011]: auc: 0.8268 | acc: 0.7528 | rmse: 0.4223
2023-12-05 17:22:08[INFO]: [EPOCH=012]: loss_main: 0.6205
2023-12-05 17:22:08[INFO]: [EPOCH=012]: auc: 0.8248 | acc: 0.7519 | rmse: 0.4225
2023-12-05 17:22:09[INFO]: [EPOCH=013]: loss_main: 0.6611
2023-12-05 17:22:09[INFO]: [EPOCH=013]: auc: 0.8259 | acc: 0.7519 | rmse: 0.4219
2023-12-05 17:22:09[INFO]: [EPOCH=014]: loss_main: 0.6614
2023-12-05 17:22:09[INFO]: [EPOCH=014]: auc: 0.8258 | acc: 0.7519 | rmse: 0.4213
2023-12-05 17:22:09[INFO]: [EPOCH=015]: loss_main: 0.6601
2023-12-05 17:22:09[INFO]: [EPOCH=015]: auc: 0.8259 | acc: 0.7519 | rmse: 0.4209
2023-12-05 17:22:10[INFO]: [EPOCH=016]: loss_main: 0.6293
2023-12-05 17:22:10[INFO]: [EPOCH=016]: auc: 0.8258 | acc: 0.7491 | rmse: 0.4223
2023-12-05 17:22:10[INFO]: [EPOCH=017]: loss_main: 0.6418
2023-12-05 17:22:10[INFO]: [EPOCH=017]: auc: 0.8266 | acc: 0.7528 | rmse: 0.4202
2023-12-05 17:22:11[INFO]: [EPOCH=018]: loss_main: 0.6573
2023-12-05 17:22:11[INFO]: [EPOCH=018]: auc: 0.8266 | acc: 0.7528 | rmse: 0.4199
2023-12-05 17:22:11[INFO]: [EPOCH=019]: loss_main: 0.6567
2023-12-05 17:22:11[INFO]: [EPOCH=019]: auc: 0.8266 | acc: 0.7528 | rmse: 0.4196
2023-12-05 17:22:11[INFO]: Update best epoch as [20] for auc!
2023-12-05 17:22:11[INFO]: [EPOCH=020]: loss_main: 0.6540
2023-12-05 17:22:11[INFO]: [EPOCH=020]: auc: 0.8276 | acc: 0.7537 | rmse: 0.4186
2023-12-05 17:22:12[INFO]: Update best epoch as [21] for auc!
2023-12-05 17:22:12[INFO]: [EPOCH=021]: loss_main: 0.6078
2023-12-05 17:22:12[INFO]: [EPOCH=021]: auc: 0.8295 | acc: 0.7537 | rmse: 0.4178
2023-12-05 17:22:12[INFO]: Update best epoch as [22] for auc!
2023-12-05 17:22:12[INFO]: [EPOCH=022]: loss_main: 0.6547
2023-12-05 17:22:12[INFO]: [EPOCH=022]: auc: 0.8295 | acc: 0.7537 | rmse: 0.4176
2023-12-05 17:22:13[INFO]: Update best epoch as [23] for auc!
2023-12-05 17:22:13[INFO]: [EPOCH=023]: loss_main: 0.6545
2023-12-05 17:22:13[INFO]: [EPOCH=023]: auc: 0.8298 | acc: 0.7547 | rmse: 0.4168
2023-12-05 17:22:13[INFO]: Update best epoch as [24] for auc!
2023-12-05 17:22:13[INFO]: [EPOCH=024]: loss_main: 0.6531
2023-12-05 17:22:13[INFO]: [EPOCH=024]: auc: 0.8298 | acc: 0.7547 | rmse: 0.4166
2023-12-05 17:22:13[INFO]: Update best epoch as [25] for auc!
2023-12-05 17:22:13[INFO]: [EPOCH=025]: loss_main: 0.6033
2023-12-05 17:22:13[INFO]: [EPOCH=025]: auc: 0.8300 | acc: 0.7547 | rmse: 0.4168
2023-12-05 17:22:14[INFO]: Update best epoch as [26] for auc!
2023-12-05 17:22:14[INFO]: [EPOCH=026]: loss_main: 0.6524
2023-12-05 17:22:14[INFO]: [EPOCH=026]: auc: 0.8300 | acc: 0.7547 | rmse: 0.4166
2023-12-05 17:22:14[INFO]: Update best epoch as [27] for auc!
2023-12-05 17:22:14[INFO]: [EPOCH=027]: loss_main: 0.6529
2023-12-05 17:22:14[INFO]: [EPOCH=027]: auc: 0.8300 | acc: 0.7547 | rmse: 0.4165
2023-12-05 17:22:15[INFO]: Update best epoch as [28] for auc!
2023-12-05 17:22:15[INFO]: [EPOCH=028]: loss_main: 0.6521
2023-12-05 17:22:15[INFO]: [EPOCH=028]: auc: 0.8300 | acc: 0.7547 | rmse: 0.4164
2023-12-05 17:22:15[INFO]: Update best epoch as [29] for auc!
2023-12-05 17:22:15[INFO]: [EPOCH=029]: loss_main: 0.5979
2023-12-05 17:22:15[INFO]: [EPOCH=029]: auc: 0.8339 | acc: 0.7584 | rmse: 0.4136
2023-12-05 17:22:15[INFO]: Update best epoch as [30] for auc!
2023-12-05 17:22:15[INFO]: [EPOCH=030]: loss_main: 0.6491
2023-12-05 17:22:15[INFO]: [EPOCH=030]: auc: 0.8347 | acc: 0.7584 | rmse: 0.4135
2023-12-05 17:22:16[INFO]: Update best epoch as [31] for auc!
2023-12-05 17:22:16[INFO]: [EPOCH=031]: loss_main: 0.6515
2023-12-05 17:22:16[INFO]: [EPOCH=031]: auc: 0.8347 | acc: 0.7584 | rmse: 0.4134
2023-12-05 17:22:16[INFO]: Update best epoch as [32] for auc!
2023-12-05 17:22:16[INFO]: [EPOCH=032]: loss_main: 0.6513
2023-12-05 17:22:16[INFO]: [EPOCH=032]: auc: 0.8347 | acc: 0.7584 | rmse: 0.4133
2023-12-05 17:22:17[INFO]: Update best epoch as [33] for auc!
2023-12-05 17:22:17[INFO]: [EPOCH=033]: loss_main: 0.6220
2023-12-05 17:22:17[INFO]: [EPOCH=033]: auc: 0.8355 | acc: 0.7593 | rmse: 0.4128
2023-12-05 17:22:17[INFO]: Update best epoch as [34] for auc!
2023-12-05 17:22:17[INFO]: [EPOCH=034]: loss_main: 0.6188
2023-12-05 17:22:17[INFO]: [EPOCH=034]: auc: 0.8387 | acc: 0.7603 | rmse: 0.4113
2023-12-05 17:22:17[INFO]: [EPOCH=035]: loss_main: 0.6505
2023-12-05 17:22:17[INFO]: [EPOCH=035]: auc: 0.8387 | acc: 0.7603 | rmse: 0.4112
2023-12-05 17:22:18[INFO]: [EPOCH=036]: loss_main: 0.6506
2023-12-05 17:22:18[INFO]: [EPOCH=036]: auc: 0.8387 | acc: 0.7603 | rmse: 0.4111
2023-12-05 17:22:18[INFO]: [EPOCH=037]: loss_main: 0.6475
2023-12-05 17:22:18[INFO]: [EPOCH=037]: auc: 0.8383 | acc: 0.7593 | rmse: 0.4116
2023-12-05 17:22:19[INFO]: Update best epoch as [38] for auc!
2023-12-05 17:22:19[INFO]: [EPOCH=038]: loss_main: 0.5918
2023-12-05 17:22:19[INFO]: [EPOCH=038]: auc: 0.8406 | acc: 0.7612 | rmse: 0.4098
2023-12-05 17:22:19[INFO]: Update best epoch as [39] for auc!
2023-12-05 17:22:19[INFO]: [EPOCH=039]: loss_main: 0.6495
2023-12-05 17:22:19[INFO]: [EPOCH=039]: auc: 0.8406 | acc: 0.7612 | rmse: 0.4097
2023-12-05 17:22:19[INFO]: Update best epoch as [40] for auc!
2023-12-05 17:22:19[INFO]: [EPOCH=040]: loss_main: 0.6499
2023-12-05 17:22:19[INFO]: [EPOCH=040]: auc: 0.8406 | acc: 0.7612 | rmse: 0.4097
2023-12-05 17:22:20[INFO]: Update best epoch as [41] for auc!
2023-12-05 17:22:20[INFO]: [EPOCH=041]: loss_main: 0.6487
2023-12-05 17:22:20[INFO]: [EPOCH=041]: auc: 0.8406 | acc: 0.7612 | rmse: 0.4096
2023-12-05 17:22:20[INFO]: [EPOCH=042]: loss_main: 0.5842
2023-12-05 17:22:20[INFO]: [EPOCH=042]: auc: 0.8398 | acc: 0.7612 | rmse: 0.4099
2023-12-05 17:22:21[INFO]: [EPOCH=043]: loss_main: 0.6482
2023-12-05 17:22:21[INFO]: [EPOCH=043]: auc: 0.8398 | acc: 0.7612 | rmse: 0.4098
2023-12-05 17:22:21[INFO]: [EPOCH=044]: loss_main: 0.6495
2023-12-05 17:22:21[INFO]: [EPOCH=044]: auc: 0.8398 | acc: 0.7612 | rmse: 0.4098
2023-12-05 17:22:21[INFO]: [EPOCH=045]: loss_main: 0.6488
2023-12-05 17:22:21[INFO]: [EPOCH=045]: auc: 0.8398 | acc: 0.7612 | rmse: 0.4098
2023-12-05 17:22:22[INFO]: [EPOCH=046]: loss_main: 0.5842
2023-12-05 17:22:22[INFO]: [EPOCH=046]: auc: 0.8400 | acc: 0.7603 | rmse: 0.4102
2023-12-05 17:22:22[INFO]: [EPOCH=047]: loss_main: 0.6442
2023-12-05 17:22:22[INFO]: [EPOCH=047]: auc: 0.8392 | acc: 0.7593 | rmse: 0.4109
2023-12-05 17:22:23[INFO]: [EPOCH=048]: loss_main: 0.6489
2023-12-05 17:22:23[INFO]: [EPOCH=048]: auc: 0.8392 | acc: 0.7593 | rmse: 0.4108
2023-12-05 17:22:23[INFO]: [EPOCH=049]: loss_main: 0.6488
2023-12-05 17:22:23[INFO]: [EPOCH=049]: auc: 0.8392 | acc: 0.7593 | rmse: 0.4108
2023-12-05 17:22:24[INFO]: [EPOCH=050]: loss_main: 0.6273
2023-12-05 17:22:24[INFO]: [EPOCH=050]: auc: 0.8378 | acc: 0.7584 | rmse: 0.4116
2023-12-05 17:22:24[INFO]: Suggest to stop training now
2023-12-05 17:22:24[INFO]: [EPOCH=051]: loss_main: 0.6018
2023-12-05 17:22:24[INFO]: [EPOCH=051]: auc: 0.8390 | acc: 0.7612 | rmse: 0.4100
2023-12-05 17:22:24[INFO]: ==============================
2023-12-05 17:22:24[INFO]: [For auc], the Best Epoch is: 41, the value=0.8406
2023-12-05 17:22:24[INFO]: [EPOCH=041]: loss_main: 0.6487
2023-12-05 17:22:24[INFO]: [EPOCH=041]: auc: 0.8406 | acc: 0.7612 | rmse: 0.4096
2023-12-05 17:22:24[INFO]: ==============================
2023-12-05 17:22:24[INFO]: Training Completed!
2023-12-05 17:22:24[INFO]: auc: 0.8495329979603814
2023-12-05 17:22:24[INFO]: acc: 0.7607276119402985
2023-12-05 17:22:24[INFO]: rmse: 0.4068409766051325
2023-12-05 17:22:24[INFO]: doa_all: 0.9204478032162962
2023-12-05 17:22:24[INFO]: ====================
2023-12-05 17:22:24[INFO]: All Fold Mean auc = 0.8495329979603814
2023-12-05 17:22:24[INFO]: All Fold Mean acc = 0.7607276119402985
2023-12-05 17:22:24[INFO]: All Fold Mean rmse = 0.4068409766051325
2023-12-05 17:22:24[INFO]: All Fold Mean doa_all = 0.9204478032162962
2023-12-05 17:22:24[INFO]: Task: 2023-12-05-172202 Completed!
